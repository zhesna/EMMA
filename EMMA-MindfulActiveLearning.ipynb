{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy as sc\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####preparing data\n",
    "Budget_range=[ 5,20,40,60,80,100,120,140,160,180,200]\n",
    "\n",
    "myrandommatrix=pd.read_csv('myrandommatrix.csv')\n",
    "myrandommatrix=myrandommatrix.values\n",
    "memory_strength=0.02  \n",
    "subjects_all=[1,2,3,4,5,6,7,8]\n",
    "\n",
    "\n",
    "activities=['sit','stand', 'lying_back', 'ascend_stairs','descend_stairs', 'run_treadmill', 'stepper', 'cycle_horizontal','rowing', 'jumping']\n",
    "\n",
    "for subjects in subjects_all:\n",
    "    acc_all=[]\n",
    "    presic_all=[]\n",
    "    recall_all=[]\n",
    "    f1_all=[]\n",
    "    B2=0\n",
    "    myiteration=10\n",
    "\n",
    "    for Budget in Budget_range:\n",
    "        acc_result_sum=0\n",
    "        presic_result_sum=0\n",
    "        recall_result_sum=0\n",
    "        f1_result_sum=0\n",
    "\n",
    "        for myx in range(myiteration):\n",
    "            myrandomlist=myrandommatrix[myx,:]\n",
    "\n",
    "            if Budget==Budget_range[0]:\n",
    "                train_whole=pd.read_csv('.\\\\sub%s-train.csv'%subjects)\n",
    "                train_labeled_whole=pd.read_csv('.\\\\sub%s-train-labeled.csv'%subjects)\n",
    "                train_unlabeled_whole=pd.read_csv('.\\\\sub%s-train-unlabeled.csv'%subjects)\n",
    "                train_unlabeled_whole=train_unlabeled_whole.dropna()\n",
    "                index_col=train_labeled_whole.shape[1]\n",
    "\n",
    "                test_whole=pd.read_csv('.\\\\sub%s-test.csv'%subjects)\n",
    "                test=test_whole.iloc[:, 0:index_col-2]\n",
    "                label_test=test_whole.iloc[:, index_col-2]\n",
    "                test = pd.DataFrame(scale(test), index=test.index, columns=test.columns)\n",
    "                test_whole.iloc[:, 0:index_col-2]=test\n",
    "\n",
    "                train_labeled=train_labeled_whole.iloc[:, 0:index_col-2]\n",
    "                label=train_labeled_whole.iloc[:, index_col-2]\n",
    "                train_labeled = pd.DataFrame(scale(train_labeled), index=train_labeled.index, columns=train_labeled.columns)\n",
    "                train_labeled_whole.iloc[:, 0:index_col-2]=train_labeled\n",
    "\n",
    "                train_unlabeled=train_unlabeled_whole.iloc[:, 0:index_col-2]\n",
    "                label_unlabled=train_unlabeled_whole.iloc[:, index_col-2]\n",
    "                train_unlabeled = pd.DataFrame(scale(train_unlabeled), index=train_unlabeled.index, columns=train_unlabeled.columns)\n",
    "                train_unlabeled_whole.iloc[:, 0:index_col-2]=train_unlabeled\n",
    "\n",
    "                time=train_unlabeled_whole.iloc[:, index_col-1]\n",
    "                time=time/86400\n",
    "                confidence_error=np.exp(-1*time/memory_strength)\n",
    "                train_unlabeled_whole['confidence_error']=confidence_error\n",
    "\n",
    "            else:\n",
    "                train_labeled_whole=train_labeled_whole_reference\n",
    "                train_unlabeled_whole=train_unlabeled_whole_reference\n",
    "                train_labeled=train_labeled_whole.iloc[:, 0:index_col-2]\n",
    "                label=train_labeled_whole.iloc[:, index_col-2]\n",
    "                train_unlabeled=train_unlabeled_whole.iloc[:, 0:index_col-2]\n",
    "                label_unlabled=train_unlabeled_whole.iloc[:, index_col-2]\n",
    "                confidence_error=confidence_error_reference\n",
    "\n",
    "            ############################################\n",
    "            for xx in range(Budget-B2):\n",
    "                svm_model_linear = SVC(kernel = 'linear', C = 1, probability=True).fit(train_labeled, label)\n",
    "                predictions1_prob = svm_model_linear.predict_proba(train_unlabeled)\n",
    "                predictions1 = svm_model_linear.predict(train_unlabeled)\n",
    "                entropy=entroy_calculate(predictions1_prob)\n",
    "\n",
    "\n",
    "                evaluate_factor= entropy* confidence_error\n",
    "                train_unlabeled_whole['evaluate_factor']=evaluate_factor\n",
    "\n",
    "                train_unlabeled_whole=train_unlabeled_whole.sort_values(by=['evaluate_factor'], ascending=False)\n",
    "                train_unlabeled_whole=train_unlabeled_whole.reset_index(drop=True)\n",
    "                train_unlabeled=train_unlabeled_whole.iloc[:, 0:index_col-2]\n",
    "                label_unlabled=train_unlabeled_whole.iloc[:, index_col-2]\n",
    "                confidence_error=train_unlabeled_whole.iloc[:, index_col]\n",
    "\n",
    "                xx1=xx+B2\n",
    "                query_label_assign=query_label_assign_calculate(confidence_error,label_unlabled,xx1, myrandomlist)\n",
    "\n",
    "                train_labeled_whole=train_labeled_whole.append(train_unlabeled_whole.iloc[0, 0:index_col])\n",
    "                train_labeled_whole=train_labeled_whole.reset_index(drop=True)\n",
    "                train_labeled_whole.iloc[-1, index_col-2]=query_label_assign\n",
    "                train_labeled=train_labeled_whole.iloc[:, 0:index_col-2]\n",
    "                label=train_labeled_whole.iloc[:, index_col-2]\n",
    "\n",
    "                train_unlabeled_whole=train_unlabeled_whole.drop([0])\n",
    "                train_unlabeled_whole=train_unlabeled_whole.reset_index(drop=True)\n",
    "\n",
    "                #############CALCULATE ACCURACY\n",
    "                #####Finally predict output and measure accuracy (confusion matrix)\n",
    "            svm_model_linear = SVC(kernel = 'linear', C = 1, probability=True).fit(train_labeled, label)\n",
    "            my_predictions = svm_model_linear.predict(test.iloc[:, 0:index_col-2])\n",
    "    #         label_test=test.iloc[:, index_col-2]\n",
    "            my_accuracy=accuracy_score(my_predictions, label_test)\n",
    "            my_precision=precision_score(my_predictions, label_test, average='macro')\n",
    "            my_recall=recall_score(my_predictions, label_test, average='macro')\n",
    "            my_f1=f1_score(my_predictions, label_test, average='macro')\n",
    "\n",
    "            acc_result_sum+=my_accuracy\n",
    "            presic_result_sum+=my_precision\n",
    "            recall_result_sum+=my_recall\n",
    "            f1_result_sum+=my_f1\n",
    "\n",
    "            #####cerate reference sets\n",
    "            if myx==myiteration-1:\n",
    "                train_labeled_whole_reference=train_labeled_whole\n",
    "                train_unlabeled_whole_reference=train_unlabeled_whole\n",
    "                confidence_error_reference=train_unlabeled_whole_reference.iloc[:, index_col]\n",
    "\n",
    "\n",
    "        acc_average=acc_result_sum/float(myiteration)\n",
    "        presic_average=presic_result_sum/float(myiteration)\n",
    "        recall_average=recall_result_sum/float(myiteration)\n",
    "        f1_average=f1_result_sum/float(myiteration)\n",
    "\n",
    "        acc_all.append(acc_average)\n",
    "        presic_all.append(presic_average)\n",
    "        recall_all.append(recall_average)\n",
    "        f1_all.append(f1_average)\n",
    "        B2=Budget#############################################INNNNNNNNNNNNNNNNNNNNNNNN\n",
    "    print(acc_all)\n",
    "    print(presic_all)\n",
    "    print(recall_all)\n",
    "    print(f1_all)\n",
    "\n",
    "##test plot\n",
    "plt.plot(Budget_range,acc_all, c=\"blue\", label='entropy by error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entroy_calculate(predictions1_prob):\n",
    "    entropy=[None] * len(predictions1_prob)\n",
    "    for j in range(len(predictions1_prob)):\n",
    "        entropy[j]=sc.stats.entropy(predictions1_prob[j])\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_label_assign_calculate(confidence_error,label_unlabled,xx1, myrandomlist):\n",
    "    query_label_assign=''\n",
    "    query_real_label=label_unlabled[0]\n",
    "    \n",
    "    myrandom=myrandomlist[xx1]\n",
    "    if myrandom <= confidence_error[0]*100:\n",
    "        query_label_assign=query_real_label\n",
    "    else:\n",
    "        myrandom2=np.random.randint(0,9)\n",
    "        if query_real_label!=activities[myrandom2]:\n",
    "            query_label_assign=activities[myrandom2]\n",
    "        elif myrandom2!=9:\n",
    "            query_label_assign=activities[myrandom2+1]\n",
    "        elif myrandom2==9:\n",
    "            query_label_assign=activities[0]\n",
    "    return query_label_assign"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
